# Project name
## Executive Summary
Cloud providers like Azure, Google, and AWS have changed the way organizations build out their infrastructure. By nature, the cloud tends to be more "open" due to the fact that it is operating on shared hardware owned by someone else (the cloud provider). This can present risks, though. One of the risks that has been widely publicized is that of overly permissive S3 buckets in AWS. There are plenty of news stories about data being leaked via an S3 bucket that was publicly shared unintentionally. These misconfigurations can lead to lawsuits, bad press, and other negative outcomes for businesses. There is a need for more detailed baselines for S3 buckets in order to minimize sensitive data leakage.

The S3 Baseline Project aims to fix that problem of misconfigured S3 buckets leaking sensitive data by providing actionable baselines which security professionals and cloud administrators can use to secure their S3 buckets. 

## Project Goals
The project goals were: 
- Come up with a list of best practice security hardening settings for S3 buckets
- Present that information to the public, in a form that would be easily digested by less technical AWS administrators
- Provide non-AWS experts with a resource to establish some level of security relating to their S3 buckets
- Test the delivered guide with a real-world, non-technical user to determine usefulness and needed changes
- Tweak the guide as needed to make it more understandable

## Project Methodology
## Literature Review:
In order to get a sense of what work had already been done in the S3 bucket space a thorough literature review was performed. The literature review as it pertains to this project is broken up into two pieces: 
1. Gather information on common security best practices, industry standards, and regulatory requirements related to securing S3 buckets
2. Analyze past security incidents and data breaches involving misconfigured S3 buckets to identify common attack vectors and vulnerabilities

A cross-section of research papers related to S3 bucket security are listed in the table below. 

| Article | Date Published | Description/Summary |
| -- | -- | -- |
| There's a Hole in that Bucket!: A Large-scale Analysis of Misconfigured S3 Buckets |2018| **Introduction**: Cloud storage services, such as Amazon S3 (Simple Storage Service), offer cost-effectiveness and ease of use, appealing to hobbyists and businesses alike. The proliferation of cloud storage, accessed through user-friendly APIs, is reducing barriers for developers by eliminating the need for complex in-house storage setups. Amazon S3 provides a reliable and scalable infrastructure, accessible via web console or programmatically, facilitating seamless integration into applications. Custom domain referencing is enabled by setting up CNAME resource records. **Methods**: This study investigates the prevalence and impact of misconfigurations in Amazon S3 buckets. We automatically identify and validate publicly listable buckets, employing various discovery methods. Candidate bucket names are filtered and verified for public readability or writability. They also examine publicly accessible websites referencing writable buckets to assess the potential for resource infection attacks. **Results**: The tool, implemented in Python, effectively analyzes buckets in parallel. Using a sample set size of k = 30, they determine bucket readability. While the exposure of ACL permissions to anonymous users is identified, they emphasize that this is not inherently a security breach. Analysis reveals 3,415 buckets with writable ACLs for anonymous users and 3,446 buckets with writable ACLs for authenticated users. **Discussion**: The study prompts ethical considerations regarding large-scale scans and underscores the necessity of precautions to mitigate potential risks. The study emphasizes that the experiments focused solely on identifying misconfigurations without accessing user data. The methodology relies on HTTP requests and file extension analysis to assess sensitive exposure. **Conclusion**: This research highlights security implications associated with Amazon S3 usage, aiming to raise awareness and caution users about real-world security risks. The automated tool facilitates the discovery and verification of public S3 buckets, revealing significant proportions vulnerable to unauthorized access. Over 200 readable buckets were found to leak sensitive data.|
| Swinhoe, D. What are Amazon Zelkova and Tiros? AWS looks to reduce S3 configuration errors | 2018 |**Introduction:** According to Skyhigh Networks, a notable percentage of Amazon S3 buckets have unrestricted public access, while a significant portion remains unencrypted. To address AWS S3 configuration errors, Amazon is developing two new tools – Zelkova and Tiros – aimed at enhancing visibility into data and resource access. Despite previous security initiatives by AWS, organizations such as Verizon, Booz Allen Hamilton, and others have experienced data exposure due to configuration errors. **Methods:** Amazon's efforts to improve AWS security include the launch of Macie, a machine learning tool for sensitive data discovery, and features like default encryption and permission checks for S3. Nevertheless, challenges persist due to a lack of user education, complex deployments, and the rapid expansion of cloud services, often deployed without the oversight of security teams. **Results:** AWS's new tools aim to mitigate human error and minimize the risk of data leaks by providing enhanced security verification capabilities before infrastructure changes are implemented. However, while these tools offer benefits, there are also potential downsides, as highlighted by some experts. **Discussion:** The introduction of Zelkova and Tiros reflects AWS's commitment to bolstering security measures. However, the effectiveness of these tools may depend on user education, the complexity of deployments, and the evolving nature of cloud environments. Balancing the benefits and potential drawbacks of these tools is crucial for organizations aiming to enhance their AWS security posture. **Conclusion:** As AWS continues to innovate in cloud security, the introduction of Zelkova and Tiros signifies a proactive approach to addressing configuration errors and minimizing data leakage risks. While these tools offer promising solutions, their successful implementation will require careful consideration of various factors, including user education and the dynamic nature of cloud environments.|
| Cloud based automated encryption approach to prevent S3 bucket leakage using AWS Lambda | 2022 | **Introduction**: The cloud, composed of hardware, software, databases, and associated operations, offers scalable and cost-effective computing services. Utilized widely in remote workplaces, distributed storage services leverage APIs to streamline interactions between system administrators and developers. AWS cloud services, along with other major providers like Google Cloud and Microsoft Azure, offer various benefits, including data compliance, scalability, and cost-effectiveness. **Objectives**: This report aims to explore methods for enhancing data privacy in cloud platforms, particularly focusing on protecting data within AWS S3 buckets through automated encryption. **Methods**: The report discusses the challenges of data leakage in private S3 buckets, highlighting the vulnerability of bucket names in revealing sensitive information. A methodology for restricting the flow of sensitive data from AWS S3 buckets is presented, utilizing tools like S3Scanner and AWS CloudFormation for secure bucket configuration. **Results**: Implementation and evaluation of the proposed methodology demonstrate the effectiveness of automated encryption for S3 buckets. A template designed for CloudFormation streamlines resource provisioning and administration, embedding AWS Lambda encryption functions and IAM roles for enhanced security. **Conclusion**: Automated encryption techniques, such as those demonstrated in this report, offer a robust solution for protecting data stored in AWS S3 buckets. Leveraging AWS CloudFormation and Lambda can significantly enhance cloud security and privacy, ensuring timely action against potential threats. As security and privacy are intertwined, adopting such automated approaches is crucial for safeguarding sensitive information in cloud environments.|
| Security best practices for Amazon S3 | NA  | **Introduction**: The article "Security Best Practices for Amazon S3" by AWS offers detailed guidance on securing data stored in Amazon S3 (Simple Storage Service). It focues on the importance of implementing robust security measures to protect sensitive information from unauthorized access and data breaches. **Key Points**: **Access Control**: The article emphasizes the significance of properly configuring access control settings using IAM policies, bucket policies, and Access Control Lists (ACLs) to restrict unauthorized access to S3 buckets and objects. **Encryption**: It discusses various options for server-side encryption, including SSE-S3, SSE-KMS, and SSE-C, to ensure the confidentiality and integrity of data stored in S3. **Monitoring and Logging**: Proper monitoring and logging are essential for detecting and responding to security incidents. The article explains how to enable logging and set up notifications for S3 events using Amazon CloudWatch and AWS CloudTrail. **Amazon S3 Block Public Access**: To prevent accidental exposure of data to the public internet, the article recommends enabling Amazon S3 Block Public Access settings at the account level. Data Classification and Access Management: The importance of classifying data based on its sensitivity and implementing appropriate access controls is emphasized to ensure compliance and mitigate security risks. **Conclusion**: Overall, the article provides comprehensive guidance on implementing security best practices to safeguard data stored in Amazon S3, covering access control, encryption, monitoring, and compliance considerations. Implementing these measures is crucial for maintaining the security and integrity of data in cloud environments. |
| AWS security cookbook : practical solutions for managing security policies, monitoring, auditing, and compliance with AWS | 2020 | **Introduction**: The book "AWS Security Cookbook" offers practical solutions for securing Amazon Web Services (AWS) infrastructure by implementing security policies, monitoring tools, and compliance measures. It emphasizes the importance of following cloud security best practices and explores various AWS services and features designed to enhance security. **Book Description**: The book is aimed at security consultants and professionals seeking to secure AWS infrastructure by implementing policies and following best practices. It covers a wide range of topics, including IAM and S3 policies, data security, application security, monitoring, and compliance. The discussion extends to AWS security services like Config, GuardDuty, Macie, and Inspector, along with cloud security best practices. **Audience**: The book targets IT security professionals, cloud security architects, and cloud application developers working on security-related roles who are interested in utilizing AWS infrastructure for secure application deployment. **Key Features**: **Implementing Security Solutions**: The book provides useful recipes for implementing robust cloud security solutions on AWS, with topics like permission policies, key management, and network security. **Monitoring and Auditing**: How to monitor AWS infrastructure and workloads effectively using tools like CloudWatch, CloudTrail, Config, GuardDuty, and Macie. **Preparation for Certification**: It helps prepare for the AWS Certified Security-Specialty exam by exploring different security models, compliance offerings, and best practices.
Securing Weak Points in Serverless Architectures. |  2020 |  **Introduction**: Serverless technology has transformed enterprise computing. It enables dynamic, scalable operations while freeing organizations from the burden of server management. However, despite the security advantages that serverless models offer, security is still a shared responsibility between CSPs and users. **Serverless Architectures**: In serverless computing, CSPs like AWS handle infrastructure management, enabling users to focus solely on deploying code. This abstraction layer ensures secure infrastructure, but users must still secure their data and applications. **Connected Services in a Serverless Architecture**: Critical AWS services, including Lambda, API Gateway, and IAM, are integral to serverless architectures. However, users must carefully manage permissions and configurations to maintain security and prevent unauthorized access. **Misconfigurations and Unsecure Practices**: Common misconfigurations in services like S3 and Lambda, along with unsecure coding practices, can lead to data exposure and vulnerabilities. Implementing least-privilege principles and adhering to best practices are essential for mitigating these risks. **Possible Compromise and Attack Scenarios**: Malicious actors exploit common errors and misconfigurations to execute attacks such as credential theft, privilege escalation, and financial exploitation. Vigilance and proactive security measures are necessary to prevent such incidents. **Security Measures and Recommendations**: Developers should prioritize code review, and employ application security solutions to detect and prevent attacks. Regular rotation of IAM access keys and diligent configuration management are crucial for maintaining security. **Conclusion**: While CSPs handle infrastructure security, users must actively secure their code, data, and access controls. Adherence to security best practices and vigilance are paramount for mitigating risks and ensuring the security of serverless deployments.

### Currently Available Tools: 
Some tools were found to be potentially helpful as well. Those tools will be considered when crafting the baseline configurations. A large amount of documentation is available from AWS for the below tools. 
- AWS Config helps ensure that S3 buckets adhere to the defined baseline configurations by continuously evaluating their settings and notifying administrators of any deviations.
- CloudTrail provides visibility into changes made to S3 buckets and helps organizations track user activity and API usage for security monitoring and auditing purposes.
- Security Hub aggregates and analyzes security findings from multiple AWS services, including AWS Config and CloudTrail, to identify security risks and compliance issues related to S3 buckets and other AWS resources.

## Technical Plan
This project aims to bolster S3 bucket security. In order to do that, the project was split into five key sections, each complete with subtasks needed to accomplish the overall goal, all listed below. 

### Step 1 - Develop the Baseline
Starting with the NIST SP800-53 control families, a subset of control families that is applicable to S3 was decided upon. We then went through each control within those families and decided which ones were applicable to S3. That smaller list of controls was then organized by common threats to S3 buckets. 

Some of the settings that should be addressed by the baselines included: 
- Access Control: Including prescribing access control policies for buckets, permissions for IAM users, roles, and groups. Implement the principle of least privilege to ensure that only authorized users have access to the buckets and their contents.
- Encryption: Deciding on encryption requirements for data stored in S3 buckets. Including whether or not to enable server-side encryption (SSE) with AWS-managed keys (SSE-S3) or customer-provided keys (SSE-C).
- Logging and Monitoring: Configure S3 bucket logging to track access requests and activities performed on the buckets. Enable AWS CloudTrail integration to capture API calls related to S3 bucket management and data access.

### Step 2 - Build a Sandbox Environment
We built out a sandbox environment in AWS. This allowed us to go through the various settings available to S3 administrators in the S3 console, and figure out what settings were available. It also allowed us to test actually implementing the controls we suggested, to see how easy or difficult they were to implement, and how long each would take. 

The sandbox was used to answer a few high-level questions: 
- Can the settings be applied as prescribed?
- If so, how long does the configuration take to implement?
- How difficult is the implementation?
- How might additional settings in an organization's AWS environment outside of the S3 functionality impact the baselines, such as VPCs, security groups, routing tables, etc.?

### Step 3 - Guide Writeup
Once the applicable settings were figured out, we set out to put the findings into a usable format. We decided to use GitHub Pages to host a static website so that the content would be easily accessible and also easily updatable. Content was organized as a "how-to" guide that was broken out into sections that corresponded to various threats facing S3 buckets. For example, overly permissive admin accounts, inadvertently public buckets, etc. Each section of the guide was written as a series of steps to implement required settings to address the threat. 

Then, another section of the guide was written that mapped the applicable NIST controls to their appropriate sections. For example, if I wanted to make sure I satisfied a certain NIST control, I would look it up in the NIST mapping section of the guide and find what steps I needed to implement to make sure the control was in place. 

We went through multiple iterations of the guide. At first the guide was centered around the NIST controls, but we ended up revising it and centering it around threats instead, to make the guide more user-friendly. 

### Step 4 - User Testing and Guide Tweaks
A non-IT user was recruited to test out the guide. The user was asked to sit down in front of a machine and follow the guide, actually clicking the buttons to implement the settings specified in the guide. 

One of the project members was available to observe the user. Things noted by the observer included: 
- Frustration level of the user
- Speed with which the user was able to implement the prescribed settings
- Difficulties encountered with the instructions, or the AWS interface

The user was then questioned about their experience, again surrounding the types of observations listed above. This information was taken back and discussed with the team. One of the main findings was that the guide was too verbose. That feedback was taken into account, and we ended up simplifying the guide. This was also when we reorganized the guide to center around threats instead of NIST control families. 

## Results / Findings
### Kickoff / Milestone 1
The first portion of the project focused on initial project planning. Starting with the initial idea, we started building out a project plan to accomplish the end goal of creating a set of baselines that would secure S3 buckets to a high, medium, or low level of security, according to the use case. We started by formalizing the goals of the project. Below were our original goals: 
- Provide actionable baseline for administrators to aid in securing S3 buckets
-   Meet the needs of various verticals by providing tailored baselines for different needs
-   Banks may need more stringent configurations to ensure NO sensitive data is leaked
-   Retail organizations may need moderately stringent configurations to minimize sensitive data leakage but still allow sharing of information publicly as needed
-   Certain media outlets or other oganizations may need very little configuration due to the majority of data being published publicly anyway
- Test each level of baseline provided above against reasonable attack vectors against S3 buckets to provide some assurance that the framework provides value

We then mapped out a timeline. We knew the end date of the project (the end of the semester) and had planned out the sort of work we wanted to have done by each milestone. We also put together a couple of lists. One list contained the list of risks to our project. The list started with things like time limitations, lack of knowledge of team members on AWS and S3 security concepts, and legalities surrounding our intended penetration testing of the baselines. That list of risks evolved as the project went on, when we removed certain portions of the project like penetration testing. The same was true for the list of resources needed. There were resources that did not end up being needed as the scope of the project was pared down over the course of the semester. 

We also wrote out a project methodology plan. At a high level we planned on: 
1. Conducting a literature review to identify issues facing S3 buckets and what had been studied previously in this space
2. Developing high, medium, and low security baselines each corresponding to various settings needed to enable that level of security on an S3 bucket
3. Building out a sandbox environment to implement these baselines for further testing and verification
4. Testing the baseline using Kali linux and various pen-testing tools to see if the settings worked to actually stop attacks
5. Present the findings from our pentesting in a sort of "pen test" report, mapping out how well each configuration secured the S3 buckets in question
6. Automate baseline implementation by using scripts to speed up the deployment

We broke these goals down into individual tasks and started mapping them out in GitHub Project on a Kanban board, assigning resources as needed and tracking task progress. 

### Milestone 2


(brief overview of outcomes - what did you achieve?, list milestone 1/2/3 outcomes, make an effort to logically collect and organize the findings)

(bulleted lists can also be helpful to structure your results discussion)
* outcome 1
* outcome 2
